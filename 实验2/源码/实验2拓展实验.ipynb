{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the resnet-18 here\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, ResidualBlock, num_class=10):\n",
    "        super(ResNet18, self).__init__()\n",
    "        # TODO\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # TODO\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# define the accuracy evaluation method\n",
    "def evaluate_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(loader):\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        accuracy = float(num_correct / num_samples)\n",
    "        print('Number of correct sample %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * accuracy))\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "NUM_TRAIN = 49000\n",
    "\n",
    "# 数据预处理，减去cifar-10数据均值\n",
    "transform_normal = T.Compose([\n",
    "    T.RandomCrop(32, padding=4),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.4914, 0.4822, 0.4465),(0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "\n",
    "# 加载训练集\n",
    "cifar10_train = dset.CIFAR10('数据集/data/CIFAR10', train=True, download=True, transform=transform_normal)\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64, sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "# 加载验证集\n",
    "cifar10_val = dset.CIFAR10('数据集/data/CIFAR10', train=True, download=True, transform=transform_normal)\n",
    "loader_val = DataLoader(cifar10_val, batch_size=64, sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
    "\n",
    "# 加载测试集\n",
    "cifar10_test = dset.CIFAR10('数据集/data/CIFAR10', train=False, download=True, transform=transform_normal)\n",
    "loader_test = DataLoader(cifar10_test, batch_size=64)\n",
    "\n",
    "learning_rate = 1e-2\n",
    "model = ResNet18()\n",
    "optimizer_resnet = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)\n",
    "\n",
    "for e in range(10):\n",
    "    for t, (x, y) in enumerate(loader_train):\n",
    "        model.train()\n",
    "        scores = model(x)\n",
    "        loss = F.cross_entropy(scores, y)\n",
    "\n",
    "        optimizer_resnet.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_resnet.step()\n",
    "\n",
    "        if t%100==0:\n",
    "            print('Epoch %d, iter %d, loss=%.4f' % (e, t,  loss.item()))\n",
    "    evaluate_accuracy(loader_val, model)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
